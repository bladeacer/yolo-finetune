{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea4af7d-0828-4402-b4dd-fd7069cce2ed",
   "metadata": {},
   "source": [
    "## Finetuning YOLOv11 with Buffalo and Camel labels.\n",
    "For installation and setup, view the [README](./README.md) before running this.\n",
    "\n",
    "As mentioned in the README, we will be using Roboflow for labelling our dataset.\n",
    "\n",
    "The Roboflow project is [available here](https://app.roboflow.com/stuff-avvl2/yolo-fine-y444l).\n",
    "\n",
    "## Download Annotated Dataset\n",
    "We will download the versioned dataset directly from Roboflow to the target directory.\n",
    "\n",
    "v8 format is used as it is widely supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e622d297-aa9b-448a-b678-ad5767bb253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already found at: yolo-fine-1. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from roboflow import Roboflow\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()\n",
    "target_path = Path(\"yolo-fine-1/\")\n",
    "\n",
    "if target_path.exists() and len(os.listdir(target_path)) > 5:\n",
    "    print(f\"Dataset already found at: {target_path}. Skipping download.\")\n",
    "else:\n",
    "    API_KEY = os.getenv(\"ROBOFLOW_API_KEY\")\n",
    "    rf = Roboflow(api_key=API_KEY)\n",
    "    project = rf.workspace(\"stuff-avvl2\").project(\"yolo-fine-y444l\")\n",
    "    dataset = project.version(\"1\").download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f5a592-fa17-40c5-b95a-4213e98ffc59",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37d5ca3-bd5b-44f6-b755-f8f6398d00f3",
   "metadata": {},
   "source": [
    "### Setup the logging\n",
    "\n",
    "Ultralytics support logging to wandb, comet.ml and tensorboard, out of the box. Here we only enable wandb.\n",
    "\n",
    "You need to create an account at [wandb](https://wandb.ai) and get the API key from https://wandb.ai/authorize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe04bc19-0943-4715-8d9c-f8caa0379d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import settings\n",
    "\n",
    "settings.update({\"wandb\": True,\n",
    "                 \"tensorboard\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b16e34-5f40-42cc-9d2c-b8e7366dbf6d",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We specify the path to data.yaml file, and train with a batch size of 15, and we also save the checkpoint at each epoch (save_period=1). We assume here you are connected to a GPU, hence we can specify the device to use as `device=0` to select the first GPU.  We specify the project name as balloon, this will create a folder called `balloon` to store the weights and various training artifacts such as F1, PR curves, confusion matrics, training results (loss, mAP, etc).\n",
    "\n",
    "For a complete listing of train settings, you can see [here](https://docs.ultralytics.com/modes/train/#train-settings).\n",
    "\n",
    "You can also specify the type of data [augmentation](https://docs.ultralytics.com/modes/train/#augmentation-settings-and-hyperparameters)  you want as part of the train pipeline.\n",
    "\n",
    "You can monitor your training progress at wandb (the link is given in the train output below)\n",
    "\n",
    "My GPU specs are not the best, hence we will defer training logic to the terminal via a [Python script](train_model.py) to prevent out of memory issues.\n",
    "> Even if you have good hardware, please do not run without workers set to a low value or the Jupyter kernel might crash.\n",
    "\n",
    "Below is the applied training logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0a654c-4e44-44db-9d2e-f7775cfa472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "# import torch\n",
    "\n",
    "# model = YOLO(\"yolo11s.pt\")\n",
    "\n",
    "# result = model.train(data=\"yolo-fine-1/data.yaml\",\n",
    "#                      epochs=30,\n",
    "#                      save_period=1,\n",
    "#                      batch=8,\n",
    "#                      workers=2,\n",
    "#                      device=\"0\",\n",
    "#                      project='yolo-fine',\n",
    "#                      plots=True\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983bd9f0-b70f-4a12-a95e-ff1f1c8f5534",
   "metadata": {},
   "source": [
    "After training we view the metrics on WanDB.\n",
    "\n",
    "We can run the best model (using the best checkpoint) against the validation dataset to see the overall model performance on validation set.\n",
    "\n",
    "<!-- You should see around 0.88 for mAP50, and 0.78 for mAP50-95. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47fbf205-0b5c-4c3a-9de5-5ea12d3c4302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.235 üöÄ Python-3.10.19 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 2050, 3771MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1558.3¬±926.0 MB/s, size: 65.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/data/Desktop/projects/yolo-finetune/yolo-fine-1/valid/labels.cache... 164 images, 2 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 164/164 177.2Kit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 182, len(boxes) = 308. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 3.2it/s 3.4s0.3s\n",
      "                   all        164        308      0.861      0.779      0.851      0.648\n",
      "               buffalo         76        158      0.879      0.778       0.87      0.677\n",
      "                 camel         86        150      0.843       0.78      0.831       0.62\n",
      "Speed: 0.9ms preprocess, 13.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1m/home/data/Desktop/projects/yolo-finetune/runs/detect/val\u001b[0m\n",
      "\n",
      "--- Key Metrics ---\n",
      "Overall mAP50 (map50): 0.8506\n",
      "Overall mAP50-95 (map): 0.6483\n",
      "Mean Precision (mp): 0.8611\n",
      "Mean Recall (mr): 0.7792\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo-fine/train/weights/best.pt\")\n",
    "validation_results = model.val(data=\"yolo-fine-1/data.yaml\", device=\"0\")\n",
    "\n",
    "print(\"\\n--- Key Metrics ---\")\n",
    "print(f\"Overall mAP50 (map50): {validation_results.box.map50:.4f}\")\n",
    "print(f\"Overall mAP50-95 (map): {validation_results.box.map:.4f}\")\n",
    "print(f\"Mean Precision (mp): {validation_results.box.mp:.4f}\")\n",
    "print(f\"Mean Recall (mr): {validation_results.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eaa3f0-4820-4e1a-945a-ad540f730f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
